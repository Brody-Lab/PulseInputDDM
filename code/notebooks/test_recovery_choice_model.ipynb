{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Diksha. This notebook will\n",
    "\n",
    "- Generate some simulated click times and trial durations\n",
    "- Generate some simulated choices from a model based on a set of generative parameters\n",
    "- Maximize the likelihood of the parameters given the data\n",
    "- Compute the Hessian of the ML parameters\n",
    "- Verify that the generative parameters can be recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(48);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot, StatsBase, JLD, Pandas, DataFrames, Distributions\n",
    "@everywhere using choice_observation, latent_DDM_common_functions, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 53, \"exp\", 2, 5.0, 50000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some constants\n",
    "dt,n,map_str,N,c,ntrials = 1e-2,53,\"exp\",2,5.,Int(5e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of the latent model\n",
    "pz = DataFrames.DataFrame(generative = vcat(1e-6,10.,-0.5,40.,1.,0.8,0.02), \n",
    "    name = vcat(\"σ_i\",\"B\", \"λ\", \"σ_a\",\"σ_s\",\"ϕ\",\"τ_ϕ\"),\n",
    "    fit = vcat(falses(1),trues(4),trues(2)),\n",
    "    initial = vcat(1.,5.,-5,100.,2.,0.2,0.08));\n",
    "\n",
    "#initialize any parameter that is not going to be fit to its generative value\n",
    "pz[:initial][pz[:fit] .== false] = pz[:generative][pz[:fit] .== false];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for the choice observation\n",
    "pd = DataFrames.DataFrame(generative = 0.1, name = \"bias\", fit = true, initial = 0.);\n",
    "#ammend to the latent parameter dataframe\n",
    "pchoice = vcat(pz,pd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate some simulated clicks times and trial durations\n",
    "data = latent_DDM_common_functions.sample_clicks(ntrials,dt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate choices from the model given the generative parameters\n",
    "choice_observation.sampled_dataset!(data,pchoice[:generative]; num_reps=1, rng=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-11794.359448028483"
      ],
      "text/plain": [
       "-11794.359448028483"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the likelihood of the data given the generative parameters\n",
    "choice_observation.do_LL(pchoice[:generative],dt,data,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     2.732715e+04     5.231976e+03\n",
      "     1     1.972505e+04     1.510253e+04\n",
      "     2     1.506637e+04     3.192668e+04\n",
      "     3     1.336507e+04     1.675301e+04\n",
      "     4     1.260324e+04     2.423752e+03\n",
      "     5     1.198576e+04     1.723058e+03\n",
      "     6     1.197915e+04     1.210649e+03\n",
      "     7     1.197543e+04     1.193942e+03\n",
      "     8     1.193083e+04     3.243761e+03\n",
      "     9     1.182682e+04     3.171932e+02\n",
      "    10     1.181540e+04     9.849784e+02\n"
     ]
    }
   ],
   "source": [
    "#find the ML parameters\n",
    "pchoice[:final],opt_output,state = choice_observation.do_optim(copy(pchoice[:initial]),\n",
    "    pchoice[:fit],dt,data,n;map_str=map_str);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the Hessian around the ML parameters\n",
    "pchoice[:CI_z_plus], pchoice[:CI_z_minus], H = choice_observation.do_H(pchoice[:final],pchoice[:fit],\n",
    "    dt,data,n;map_str=map_str)\n",
    "\n",
    "#identify which ML parameters have generative parameters within the CI \n",
    "pchoice[:within_bounds] = (pchoice[:CI_z_minus] .< pchoice[:generative]) .& (pchoice[:CI_z_plus] .> pchoice[:generative]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pchoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
