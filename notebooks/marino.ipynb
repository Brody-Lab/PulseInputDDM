{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(44);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using pulse_input_DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/bucket/labs/brody/vdtang/P055_processed\"\n",
    "ratnames=[\"P055\"]\n",
    "sessids=[[17061800,18041700,16052600,16070500,16111700,18010300,18022600,17122200,\n",
    "        17081200,17092600,17051900,18030500,17011800,18012200,17011500,17062500,\n",
    "        17112700,18032700,16082200,18060800,18032500,17082900,17080500,17081000,\n",
    "        17052300,17090800,17090900,18041500,18040500,17122000]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of the latent model\n",
    "pz = Dict(\"name\" => vcat(\"σ_i\",\"B\", \"λ\", \"σ_a\",\"σ_s\",\"ϕ\",\"τ_ϕ\"),\n",
    "    \"fit\" => vcat(trues(7)),\n",
    "    \"initial\" => vcat(2.,15.,-5.,100.,2.,0.2,0.005),\n",
    "    \"lb\" => [eps(), 4., -5., eps(), eps(), eps(), eps()],\n",
    "    \"ub\" => [10., 100, 5., 800., 40., 2., 10.])\n",
    "\n",
    "#parameters for the choice observation\n",
    "pd = Dict(\"name\" => vcat(\"bias\",\"lapse\"), \"fit\" => trues(2), \n",
    "    \"initial\" => vcat(0.,0.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = aggregate_choice_data(path, sessids, ratnames);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the click inputs at 10 ms\n",
    "data = bin_clicks!(data;dt=1e-2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: some parameter(s) at lower bound. bumped it (them) up 1/4 from the lower bound.\n",
      "└ @ pulse_input_DDM /usr/people/briandd/.julia/packages/pulse_input_DDM/edA5O/src/wrapper_functions.jl:60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     5.255149e+03     1.156880e+03\n",
      "     1     5.116243e+03     8.875782e+02\n",
      "     2     4.900577e+03     2.138011e+02\n",
      "     3     4.895523e+03     2.171708e+02\n",
      "     4     4.852006e+03     1.618516e+02\n",
      "     5     4.821839e+03     1.492736e+02\n",
      "     6     4.796827e+03     5.548819e+01\n",
      "     7     4.788745e+03     5.265261e+01\n",
      "     8     4.782937e+03     6.176447e+01\n",
      "     9     4.777379e+03     1.373893e+01\n",
      "    10     4.777127e+03     2.525360e+01\n",
      "    11     4.774601e+03     2.783452e+01\n",
      "    12     4.772160e+03     3.570138e+01\n",
      "    13     4.770569e+03     3.024035e+01\n",
      "    14     4.769563e+03     2.880265e+01\n",
      "    15     4.768599e+03     1.850554e+01\n",
      "    16     4.767813e+03     1.441823e+01\n",
      "    17     4.767020e+03     1.007484e+01\n",
      "    18     4.766396e+03     6.265240e+00\n",
      "    19     4.765841e+03     8.009592e+00\n",
      "    20     4.765601e+03     1.283242e+01\n",
      "    21     4.765267e+03     1.972953e+01\n",
      "    22     4.764995e+03     1.503726e+01\n",
      "    23     4.764809e+03     1.444278e+01\n",
      "    24     4.764664e+03     1.446476e+01\n",
      "    25     4.764497e+03     8.702463e+00\n",
      "    26     4.764343e+03     8.118261e+00\n",
      "    27     4.764195e+03     6.620016e+00\n",
      "    28     4.764061e+03     5.137376e+00\n",
      "    29     4.763933e+03     3.543381e+00\n",
      "    30     4.763851e+03     5.633641e+00\n",
      "    31     4.763783e+03     5.256031e+00\n",
      "    32     4.763728e+03     3.592562e+00\n",
      "    33     4.763694e+03     4.668097e+00\n",
      "    34     4.763662e+03     2.693793e+00\n",
      "    35     4.763641e+03     3.627667e+00\n",
      "    36     4.763621e+03     2.716692e+00\n",
      "    37     4.763605e+03     2.658018e+00\n",
      "    38     4.763593e+03     2.369731e+00\n",
      "    39     4.763581e+03     1.631402e+00\n",
      "    40     4.763570e+03     1.875525e+00\n",
      "    41     4.763560e+03     1.641293e+00\n",
      "    42     4.763552e+03     1.275962e+00\n",
      "    43     4.763547e+03     1.506729e+00\n",
      "    44     4.763542e+03     1.046005e+00\n",
      "    45     4.763539e+03     1.179072e+00\n",
      "    46     4.763536e+03     1.208826e+00\n",
      "    47     4.763533e+03     8.637106e-01\n",
      "    48     4.763530e+03     9.038129e-01\n",
      "    49     4.763528e+03     8.077832e-01\n",
      "    50     4.763526e+03     1.387250e+00\n",
      "    51     4.763525e+03     6.963775e-01\n",
      "    52     4.763524e+03     1.393223e+00\n",
      "    53     4.763523e+03     6.889287e-01\n",
      "    54     4.763522e+03     6.892529e-01\n",
      "    55     4.763521e+03     1.397132e+00\n",
      "    56     4.763521e+03     1.401041e+00\n",
      "    57     4.763521e+03     1.399773e+00\n",
      "    58     4.763520e+03     6.847184e-01\n",
      "    59     4.763520e+03     6.838200e-01\n",
      "    60     4.763520e+03     6.833677e-01\n",
      "    61     4.763520e+03     6.830701e-01\n",
      "    62     4.763520e+03     6.830124e-01\n",
      "487.476827 seconds (326.80 M allocations: 35.175 GiB, 2.73% gc time)\n"
     ]
    }
   ],
   "source": [
    "#find the ML parameters with gradient descent\n",
    "@time pz, pd, = optimize_model(pz, pd, data; f_tol=1e-9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the Hessian of the LL landscape, to compute confidence intervals on the parameters\n",
    "pz, pd = compute_H_CI!(pz, pd, data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "show(DataFrame(pz),allcols=true)\n",
    "show(DataFrame(pd),allcols=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate choices from the model, given the ML parameters\n",
    "ML_data = deepcopy(data)\n",
    "sample_choices_all_trials!(ML_data, pz[\"final\"], pd[\"final\"])\n",
    "\n",
    "#compute the final click difference, which will dictate the correct choice\n",
    "ΔLR = map((nT,L,R)->diffLR(nT,L,R,data[\"dt\"])[end], data[\"nT\"], data[\"leftbups\"], data[\"rightbups\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the choices from the generative parameters and from the ML parameters\n",
    "import Pandas: qcut\n",
    "import Statistics: mean\n",
    "\n",
    "nbins = 15;\n",
    "conds,qcut_bins = qcut(ΔLR, nbins, labels=false, retbins=true);\n",
    "conds = conds .+ 1;\n",
    "\n",
    "frac_choice_ML = [mean(ML_data[\"pokedR\"][conds .== i]) for i in 1:nbins]\n",
    "frac_choice_data = [mean(data[\"pokedR\"][conds .== i]) for i in 1:nbins];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit a GLM to the generative choices and the ML choices\n",
    "using GLM\n",
    "GLM_data = glm(@formula(Y ~ X), DataFrame(X=ΔLR, Y = data[\"pokedR\"]), Binomial(), LogitLink())\n",
    "GLM_ML = glm(@formula(Y ~ X), DataFrame(X=ΔLR, Y = ML_data[\"pokedR\"]), Binomial(), LogitLink());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "\n",
    "fig = figure(figsize=(6,6))\n",
    "ax = subplot(111)\n",
    "\n",
    "scatter(qcut_bins[1:end-1] + diff(qcut_bins)/2, frac_choice_data, color=\"red\", label=\"generative\")\n",
    "scatter(qcut_bins[1:end-1] + diff(qcut_bins)/2, frac_choice_ML, color=\"grey\", label=\"ML\")\n",
    "\n",
    "plot(sort(ΔLR), sort(predict(GLM_data)), color=\"red\")\n",
    "plot(sort(ΔLR), sort(predict(GLM_ML)), color=\"grey\")\n",
    "\n",
    "ylabel(\"% poked R\")\n",
    "xlabel(L\"\\Delta{LR}\")\n",
    "ax[:spines][\"top\"][:set_color](\"none\") \n",
    "ax[:spines][\"right\"][:set_color](\"none\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed, as above, for any other datasets you wish to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessidsF = [[17061801,18041701,16052601,16070501,16111701,18010301,\n",
    "        18022601,17122201,17081201,17092601,17051901,18030501,\n",
    "        17011801,18012201,17011501,17062501,17112701,18032701,16082201,\n",
    "        18060801,18032501,17082901,17080501,17081001,\n",
    "        17052301,17090801,17090901,18041501,18040501,17122001]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save variables to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLD2.@save \"/usr/people/briandd/Projects/pulse_input_DDM.jl/data/results/marino.jld\" pz pd"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
