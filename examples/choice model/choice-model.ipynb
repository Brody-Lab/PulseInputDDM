{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook walks through the basics of generating synthetic choice data and fitting the model to that data to recover the paramaters that generated it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting these models to data to choice data alone can be computational expensive. We fit the model below using 44 cpus.\n",
    "\n",
    "`using` is the julia version of python's `import`, i.e. in incorporates the exported functions of a module into the current namespace. `Distributed` is a julia module for performing parallel computing. `addprocs()` adds some workers, which can be called by a main process if there are calls to do things in parallel. `PulseInputDDM` parallelizes the computation of the log-likelhood across trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Fitting a choice model.\n",
    "\n",
    "when `using` is called after workers have been made, i.e. above, then those modules are available on all the workers (i.e. any function called from those modules will be able to be executed on any worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PulseInputDDM, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some data\n",
    "\n",
    "Create an instance of the `θchoice` [composite type](https://docs.julialang.org/en/v1/manual/types/#Composite-Types) which contains the 9 parameters of a choice DDM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_syn = θchoice(θz=θz(σ2_i = 1., B = 13., λ = -0.5, σ2_a = 10., σ2_s = 1.0,\n",
    "    ϕ = 0.4, τ_ϕ = 0.02), bias=0.1, lapse=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgen = collect(Flatten.flatten(θ_syn));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 20K trials of the synthetic data using those parameters. change `rng` to get a different set with the same parameters. `dt` specifies the temporal binning of the data. `1e-2` has worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data = synthetic_data(;θ=θ_syn, ntrials=8_000, rng=2, dt=1e-2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PulseInputDDM` computes the log-likelihood by propogating mass of the latent distribution in time. This is done numerically by dividing the distribution up into little temporal and spatial bins. `n` is the number of spatials bins to use. `n=53` seems to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the `choiceDDM` composite type which contains the parameters and the data of a choice DDM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = choiceDDM(θ=θ_syn, data=data, n=n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see the docstring for `choiceDDM` type `?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc choiceDDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the loglikelihood of the model under the generative parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = vcat([0.1, 15., -0.1, 20., 0.5, 0.2, 0.008], [0.,0.01]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use `Flatten.reconstruct` to place the intial state into the `θchoice()` type, with each variable going into the right place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = Flatten.reconstruct(θchoice(), x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = choiceDDM(θ=θ, data=data, n=n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the loglikelihood of the model under the initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define bounds for each parameter for the optimization. Some of these are strict (i.e. variance > 0) and some are not (B < 100 seems reasonable, but B could of course be larger then 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [0., 2.,  -5., 0.,   0.,  0., 0.005, -5.0, 0.0]\n",
    "ub = [30., 100., 5., 200., 10., 1.2,  1., 5.0, 1.0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit` specifies which parameters should be learned. If they are not learned, they remain at their value from `x0`, the initial point of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = vcat(trues(9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the `choiceoptions` composite type, using `lb`, `ub`, and `fit`. `choiceoptions` specifies which parameters to fit, and the lower and upper bounds of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = choiceoptions(fit=fit, lb=lb, ub=ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc choiceoptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define bounds for each parameter for the optimization. Some of these are strict (i.e. variance > 0) and some are not (B < 100 seems reasonable, but B could of course be larger then 100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the model, using the options to define details of the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc PulseInputDDM.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, output = optimize(model, options, f_tol=1e-3, iterations = 100, extended_trace=true, show_trace=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the likelihood of the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2964.391048661696"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loglikelihood(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the gradient of the model after optimization, to ensure we are near the minimum of the loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{Float64}:\n",
       " -0.035268930600005535\n",
       "  0.08999858784521625\n",
       " -0.6998347283973927\n",
       "  0.09059444267566338\n",
       "  1.9425524414020203\n",
       "  9.990898188423424\n",
       " -3.0944021983335404\n",
       " -1.2361640079379252\n",
       "  5.96964709242075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Hessian of the model, to compute confidence bounds around the ML parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Hessian is not positive definite. Approximated by closest PSD matrix.\n",
      "│             ||ϵ||/||H|| is 0.523128861211172\n",
      "└ @ PulseInputDDM /Users/briandepasquale/Documents/GitHub/PulseInputDDM/src/base_model.jl:19\n"
     ]
    }
   ],
   "source": [
    "H = Hessian(model)\n",
    "CI, HPSD = CIs(H);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the eigenvalues of the hessian, to ensure that it is positive semidefinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{Float64}:\n",
       "     -0.050025419469309766\n",
       "     -0.0003796327464849516\n",
       "      0.00412042590508605\n",
       "      4.732316790901145\n",
       "     14.677064922676797\n",
       "     37.879545011449025\n",
       "    115.10801793426742\n",
       "  15264.399969525104\n",
       " 402944.66090952803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "eigvals(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = collect(Flatten.flatten(model.θ));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the solution is within the confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bool[1, 1, 1, 1, 1, 0, 1, 1, 1], Bool[1, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(xf - CI) .< xgen, (xf + CI) .> xgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Final objective value:     2.974295e+03\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Fminbox with BFGS\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = 1.94e-03 ≰ 1.0e-10\n",
       "    |x - x'|/|x'|          = 6.41e-05 ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = 0.00e+00 ≤ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = 0.00e+00 ≤ 1.0e-03\n",
       "    |g(x)|                 = 1.48e+00 ≰ 1.0e-03\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   3584  (vs limit 170000)\n",
       "    Iterations:    2\n",
       "    f(x) calls:    26\n",
       "    ∇f(x) calls:   16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the step-by-step values of the optimization and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = hcat(map(x-> x.metadata[\"x\"], output.trace)...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = 3,3\n",
    "fig, ax = subplots(num_rows, num_cols, figsize=(9,9))\n",
    "name = [\"σ2_i\", \"B\", \"λ\", \"σ2_a\", \"σ2_s\", \"ϕ\", \"τ_ϕ\", \"bias\", \"lapse\"]\n",
    "\n",
    "for i in 1:9\n",
    "                  \n",
    "    ax[i].plot(trace[i,:])\n",
    "    ax[i].plot(xgen[i] * ones(size(trace,2)))\n",
    "    ax[i].set_title(name[i])\n",
    "    \n",
    "    ax[i].errorbar(size(trace, 2), xf[i], yerr=CI[i], fmt=\"o\",\n",
    "        capsize=6)\n",
    "end\n",
    "\n",
    "tight_layout() \n",
    "IJulia.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = options.lb\n",
    "ub = options.ub;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the LL over the optimization domain, for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere ℓℓ(x, model) = -PulseInputDDM.loglikelihood(x, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "αs = hcat(map((lb,ub)-> range(lb + eps(), stop=ub, length=30), lb, ub));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_scan = map(i-> map(x-> ℓℓ(vcat(xf[1:i-1], x, xf[i+1:end]), model), αs[i]), 1:9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `αs` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `αs` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/GitHub/PulseInputDDM/examples/choice model/choice-model.ipynb:7"
     ]
    }
   ],
   "source": [
    "num_rows, num_cols = 3,3\n",
    "fig, ax = subplots(num_rows, num_cols, figsize=(9,9))\n",
    "name = [\"σ2_i\", \"B\", \"λ\", \"σ2_a\", \"σ2_s\", \"ϕ\", \"τ_ϕ\", \"bias\", \"lapse\"]\n",
    "\n",
    "for i in 1:9\n",
    "                  \n",
    "    ax[i].plot(αs[i], LL_scan[i], \"x\")\n",
    "    ax[i].set_title(name[i])\n",
    "    ax[i].plot(xgen[i]*ones(100), range(minimum(LL_scan[i]), stop=maximum(LL_scan[i]), length=100), \"k\")\n",
    "    ax[i].plot(xf[i]*ones(100), range(minimum(LL_scan[i]), stop=maximum(LL_scan[i]), length=100),\n",
    "        \"g--\")\n",
    "    ax[i].plot(max((xf[i] - CI[i]), lb[i]) *ones(100), range(minimum(LL_scan[i]), \n",
    "            stop=maximum(LL_scan[i]), length=100), \"r--\")\n",
    "    ax[i].plot(min((xf[i] + CI[i]), ub[i]) *ones(100), range(minimum(LL_scan[i]), \n",
    "            stop=maximum(LL_scan[i]), length=100), \"r--\")\n",
    "\n",
    "    \n",
    "end\n",
    "\n",
    "tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and reloading modeling results and saving data\n",
    "\n",
    "Use the `save_choice_model` function to save the optimized model, the options used to define the optimization, and the confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"../choice model/example_results.mat\"\n",
    "save_choice_model(save_file, model, options, CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to restart the optimization from where you stopped `reload_choice_model` will reload those model parameters and the `options`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ, options = reload_choice_model(save_file);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the choice data using `save_choice_data` and then reload it using `load_choice_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PulseInputDDM: save_choice_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_choice_data(\"../choice model/example_matfile_2.mat\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_choice_data(\"../choice model/example_matfile_2.mat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7435.988771905236"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = choiceDDM(θ=θ, data=data, n=n);\n",
    "loglikelihood(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and fitting a choice model from real data\n",
    "\n",
    "Because many neuroscientists use matlab, we use the [MAT.jl](https://github.com/JuliaIO/MAT.jl) package for IO. Data can be loaded using two conventions. One of these conventions is easier when data is saved within matlab as a .MAT file, and is described below. \n",
    "\n",
    "The package expects your data to live in a single .mat file which should contain a struct called `rawdata`. Each element of `rawdata` should have data for one behavioral trial and `rawdata` should contain the following fields with the specified structure:\n",
    "\n",
    " - `rawdata.leftbups`: row-vector containing the relative timing, in seconds, of left clicks on an individual trial. 0 seconds is the start of the click stimulus.\n",
    " - `rawdata.rightbups`: row-vector containing the relative timing in seconds (origin at 0 sec) of right clicks on an individual trial. 0 seconds is the start of the click stimulus.\n",
    " - `rawdata.T`: the duration of the trial, in seconds. The beginning of a trial is defined as the start of the click stimulus. The end of a trial is defined based on the behavioral event “cpoke_end”. This was the Hanks convention.\n",
    " - `rawdata.pokedR`: `Bool` representing the animal choice (1 = right).\n",
    " \n",
    "The example file located at `../choice model/example_matfile.mat` adheres to this convention and can be loaded using the `load_choice_data` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_choice_data(\"../choice model/example_matfile.mat\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ2 = θchoice(θz=θz(σ2_i = 2., B = 23., λ = 0.5, σ2_a = 100., σ2_s = 1.1,\n",
    "    ϕ = 0.35, τ_ϕ = 0.035), bias=0.2, lapse=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.321480367653435"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = choiceDDM(θ=θ2, data=data, n=n);\n",
    "loglikelihood(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
